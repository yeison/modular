# PyTorch inference in MAX

MAX can accelerate the inference of existing PyTorch models. These
examples show several common PyTorch models running in MAX through the
Mojo, Python, and C APIs:

## PyTorch (via TorchScript)

- BERT, [with the Mojo API](./bert-mojo-torchscript/),
[with the Python API](./bert-python-torchscript/),
and [with the C API](./bert-c-torchscript/)
- [ResNet50 with the Python API](./resnet50-python-torchscript/)
